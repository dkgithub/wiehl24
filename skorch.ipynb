{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdTerRtch+Q05J8Yh07N1D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkgithub/wiehl24/blob/main/skorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Working with PyTorch can become involved. There are many tool that try to avoid writimg out all the litlle details.\n",
        "Most commonly used is lighning. Here, we use skorch. It provides a Keras like interface that interacts smoothly with sklearn."
      ],
      "metadata": {
        "id": "NwFbqZ3WGehk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg94V2ZhGdPn",
        "outputId": "c9a54c27-7430-4759-85eb-9c97e4fe0e3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n"
          ]
        }
      ],
      "source": [
        "#!rm -rf helpers # if an enforce reinstall is necessary\n",
        "![ ! -d helpers ] && git clone --recursive https://github.com/dkgithub/erum_ml_school_helpers helpers\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget torchinfo skorch livelossplot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YolrQGO_HKC9",
        "outputId": "222b7bd6-d190-493c-9af7-53acf89ff20b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: skorch in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.10/dist-packages (0.5.5)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.11.4)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (4.66.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.7.1)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (3.2.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (3.1.3)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.2.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (23.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.5.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.3.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2023.10.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the helpers package and other software\n",
        "import helpers as hlp\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchinfo\n",
        "import skorch as sk\n",
        "from livelossplot import PlotLosses"
      ],
      "metadata": {
        "id": "CiGqNn7bIwbk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check for accelerators\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('torch',torch.__version__)\n",
        "print('device type is',device)\n",
        "if device == 'cuda' :print(torch.cuda.get_device_name())\n",
        "from os import environ\n",
        "if \"COLAB_TPU_ADDR\" in environ and environ[\"COLAB_TPU_ADDR\"]:\n",
        "  print(\"A TPU is connected.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVBtZfs9JHTf",
        "outputId": "036cd27d-5511-4f0d-ea5b-a3bbfcf754a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch 2.1.0+cu121\n",
            "device type is cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first, we define a preprocessing function that (e.g.) takes the\n",
        "# constiuents and returns another representation of them\n",
        "\n",
        "#def preprocess_constituents(constituents):\n",
        "#    return constituents[:, :120].reshape((-1, 480))\n",
        "\n",
        "def preprocess_constituents(constituents):\n",
        "  # sum all constituents to get jet 4-momenta\n",
        "  c_sum=constituents.sum(axis=1)\n",
        "  metric=np.array([1.,-1.,-1.,-1.]) #g_mu_nu\n",
        "  # calculating invariants wrt. to jet\n",
        "  c_inv=(constituents*metric*c_sum[:,None,:]).sum(axis=2)\n",
        "  return c_inv\n"
      ],
      "metadata": {
        "id": "E1kffGs-JTha"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here, we define a function to construct the datasets\n",
        "def makeDataset(name=None,nFiles=None):\n",
        "  if name not in ['train','valid','test']:\n",
        "    print(f'Need a proper data split name')\n",
        "    return\n",
        "  if name == 'train' and nFiles == None: nFiles = 2\n",
        "  else: nFiles = 1\n",
        "  c_vectors, _, labels = hlp.data.load(name, stop_file=nFiles)\n",
        "  # run the preprocessing\n",
        "  c_vectors = preprocess_constituents(c_vectors)\n",
        "  # create torch tensors from numpy arrays, map to float32,\n",
        "  # and move to GPU if available - device must be defined\n",
        "  c_tensor      = torch.from_numpy(c_vectors).float().to(device)\n",
        "  label_tensor  = torch.from_numpy(labels   ).float().to(device)\n",
        "  # Then, we create a dataset from our tensors\n",
        "  print(f'dataset {name} \\tlength',len(label_tensor),'\\tshape',c_tensor.shape)\n",
        "  return torch.utils.data.TensorDataset(c_tensor,label_tensor)"
      ],
      "metadata": {
        "id": "6H2-vgOFL6lF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct a dataloader from dataset of batch size bs\n",
        "def makeDataLoader(dataset,bs=500,shuffle=True):\n",
        "  loader  = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle = shuffle)\n",
        "  n_inner=float(len(loader))\n",
        "  print(f'The dataloader is able to produce {int(n_inner):3d} batches of {bs} data points each.')\n",
        "  return loader"
      ],
      "metadata": {
        "id": "-SOqO3m3TRuy"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = makeDataset('train')\n",
        "dataset_valid = makeDataset('valid')\n",
        "dataset_test  = makeDataset('test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE1-AlAGMfvE",
        "outputId": "8221b413-9e3d-4793-b3e4-f3ac53b84e5d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset train \tlength 100000 \tshape torch.Size([100000, 200])\n",
            "dataset valid \tlength 50000 \tshape torch.Size([50000, 200])\n",
            "dataset test \tlength 50000 \tshape torch.Size([50000, 200])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = makeDataLoader(dataset_train,500)\n",
        "valid_loader = makeDataLoader(dataset_valid,10000,False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb2lfdRVKGo3",
        "outputId": "79607dfa-fa89-4b0f-9116-ca6a840e7b95"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataloader is able to produce 200 batches of 500 data points each.\n",
            "The dataloader is able to produce   5 batches of 10000 data points each.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skorch works with callbacks. Callbacks are called at certain points in the processing loop. Especially: epoch start,epoch end, batch start and batch end. Most common callbacks, e.g. scoring are predefined."
      ],
      "metadata": {
        "id": "eb1JJM3MVqqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skorch.callbacks import EpochScoring\n",
        "auc = EpochScoring(scoring='roc_auc', lower_is_better=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k4NQy8FKcDh",
        "outputId": "6bddba2a-6442-4fa0-a3f6-02f8d2cbf543"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100000, 200), torch.Size([100000, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we construct a network\n",
        "from torch import nn\n",
        "class model(nn.Module):\n",
        "    def __init__(self,in_size=200,mid_size=200,n_layers=5):\n",
        "        super().__init__()\n",
        "        self.in_size  = in_size\n",
        "        self.mid_size = mid_size\n",
        "        self.n_layers = n_layers\n",
        "        linears = nn.ModuleList(nn.Linear(in_size,mid_size))\n",
        "        self.linears = linnears.append([nn.Linear(mid_size, mid_size) for i in range(n_layers)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ModuleList can act as an iterable, or be indexed using ints\n",
        "        for i, l in enumerate(self.linears):\n",
        "            x = self.linears[i // 2](x) + l(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "        X = self.nonlin(self.dense0(X))\n",
        "        X = self.dropout(X)\n",
        "        X = F.relu(self.dense1(X))\n",
        "        X = F.softmax(self.output(X), dim=-1)\n",
        "        return X\n",
        "\n",
        "from skorch import NeuralNetClassifier\n",
        "net = NeuralNetClassifier(\n",
        "    ClassifierModule,\n",
        "    max_epochs=50,\n",
        "    lr=0.1,\n",
        "#    callbacks=[LivePlot],\n",
        "    callbacks=[auc],\n",
        "#     device='cuda',  # uncomment this to train with CUDA\n",
        ")"
      ],
      "metadata": {
        "id": "IXiQG_GfLDoQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
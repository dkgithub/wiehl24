{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnvP2hzhnSsiUSc03RxLum",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkgithub/wiehl24/blob/main/skorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Working with PyTorch can become involved. There are many tool that try to avoid writimg out all the litlle details.\n",
        "Most commonly used is lighning. Here, we use skorch. It provides a Keras like interface that interacts smoothly with sklearn."
      ],
      "metadata": {
        "id": "NwFbqZ3WGehk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg94V2ZhGdPn",
        "outputId": "e0176d77-0f37-4ee2-971d-30140fc0faae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n"
          ]
        }
      ],
      "source": [
        "#!rm -rf helpers # if an enforce reinstall is necessary\n",
        "![ ! -d helpers ] && git clone --recursive https://github.com/dkgithub/erum_ml_school_helpers helpers\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget torchinfo skorch livelossplot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YolrQGO_HKC9",
        "outputId": "6e2541e1-7203-4b29-fffd-bbd40150ec09"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: skorch in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.10/dist-packages (0.5.5)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.11.4)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (4.66.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.7.1)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (3.2.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (3.1.3)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.2.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (23.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.5.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.3.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2023.10.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the helpers package and other software\n",
        "import helpers as hlp\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchinfo\n",
        "import skorch as sk\n",
        "from livelossplot import PlotLosses"
      ],
      "metadata": {
        "id": "CiGqNn7bIwbk"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check for accelerators\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('torch',torch.__version__)\n",
        "print('device type is',device)\n",
        "if device == 'cuda' :print(torch.cuda.get_device_name())\n",
        "from os import environ\n",
        "if \"COLAB_TPU_ADDR\" in environ and environ[\"COLAB_TPU_ADDR\"]:\n",
        "  print(\"A TPU is connected.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVBtZfs9JHTf",
        "outputId": "f90f2492-a7b6-4b74-8f6c-a1fad6b58cc0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch 2.1.0+cu121\n",
            "device type is cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first, we define a preprocessing function that (e.g.) takes the\n",
        "# constiuents and returns another representation of them\n",
        "\n",
        "#def preprocess_constituents(constituents):\n",
        "#    return constituents[:, :120].reshape((-1, 480))\n",
        "\n",
        "def preprocess_constituents(constituents):\n",
        "  # sum all constituents to get jet 4-momenta\n",
        "  c_sum=constituents.sum(axis=1)\n",
        "  metric=np.array([1.,-1.,-1.,-1.]) #g_mu_nu\n",
        "  # calculating invariants wrt. to jet\n",
        "  c_inv=(constituents*metric*c_sum[:,None,:]).sum(axis=2)\n",
        "  return c_inv\n",
        "\n"
      ],
      "metadata": {
        "id": "E1kffGs-JTha"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getData(name=None,nFiles=None):\n",
        "  if name not in ['train','valid','test']:\n",
        "    print(f'Need a proper data split name')\n",
        "    return\n",
        "  if name == 'train' and nFiles == None: nFiles = 2\n",
        "  else: nFiles = 1\n",
        "  c_vectors, _, labels = hlp.data.load(name, stop_file=nFiles)\n",
        "  # run the preprocessing\n",
        "  c_vectors = preprocess_constituents(c_vectors)\n",
        "  # create torch tensors from numpy arrays, map to float32,\n",
        "  c_tensor      = torch.from_numpy(c_vectors).float()\n",
        "  label_tensor  = torch.from_numpy(labels   ).float()\n",
        "  print(f'Data {name} - length \\t{len(c_tensor)} \\tshape {c_tensor.shape}' )\n",
        "  return c_tensor,label_tensor\n",
        ""
      ],
      "metadata": {
        "id": "Xn3n_z_cI3Th"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here, we define a function to construct the datasets\n",
        "def makeDataset(name=None,nFiles=None):\n",
        "  if name not in ['train','valid','test']:\n",
        "    print(f'Need a proper data split name')\n",
        "    return\n",
        "  if name == 'train' and nFiles == None: nFiles = 2\n",
        "  else: nFiles = 1\n",
        "  c_vectors, _, labels = hlp.data.load(name, stop_file=nFiles)\n",
        "  # run the preprocessing\n",
        "  c_vectors = preprocess_constituents(c_vectors)\n",
        "  # create torch tensors from numpy arrays, map to float32,\n",
        "  # and move to GPU if available - device must be defined\n",
        "  c_tensor      = torch.from_numpy(c_vectors).float().to(device)\n",
        "  label_tensor  = torch.from_numpy(labels   ).float().to(device)\n",
        "  # Then, we create a dataset from our tensors\n",
        "  print(f'dataset {name} \\tlength',len(label_tensor),'\\tshape',c_tensor.shape)\n",
        "  return torch.utils.data.TensorDataset(c_tensor,label_tensor)"
      ],
      "metadata": {
        "id": "FkLxS_3NhJsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train, label_train = getData('train')\n",
        "data_valid, label_valid = getData('valid')\n",
        "data_test,  label_test  = getData('test')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE1-AlAGMfvE",
        "outputId": "93f19eee-deba-4c54-dc9f-9a7cb7f322fd"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data train - length \t100000 \tshape torch.Size([100000, 200])\n",
            "Data valid - length \t50000 \tshape torch.Size([50000, 200])\n",
            "Data test - length \t50000 \tshape torch.Size([50000, 200])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we construct a network\n",
        "from torch import nn\n",
        "class myModel(nn.Module):\n",
        "  def __init__(self,in_size=200,mid_size=200,n_layers=5):\n",
        "    super().__init__()\n",
        "    self.in_size  = in_size\n",
        "    self.mid_size = mid_size\n",
        "    self.n_layers = n_layers\n",
        "    self.inLay    = nn.Linear(in_size,mid_size)\n",
        "    self.linears  = nn.ModuleList([nn.Linear(mid_size, mid_size) for i in range(n_layers)])\n",
        "    self.bnorms   = nn.ModuleList([nn.BatchNorm1d(mid_size) for i in range(n_layers)])\n",
        "    self.outLay   = nn.Linear(mid_size, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.inLay(x)\n",
        "    x = torch.relu(x)\n",
        "    # ModuleList can act as an iterable, or be indexed using ints\n",
        "    for i,lay in enumerate(self.linears):\n",
        "      x = lay(x)\n",
        "      self.bnorms[i](x)\n",
        "      x = torch.relu(x)\n",
        "    x = self.outLay(x)\n",
        "    x = torch.sigmoid(x)\n",
        "    return x\n",
        "\n",
        "# we initiate the model\n",
        "model=myModel()"
      ],
      "metadata": {
        "id": "IXiQG_GfLDoQ"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skorch works with callbacks. Callbacks are called at certain points in the processing loop. Especially: epoch start,epoch end, batch start and batch end. Most common callbacks, e.g. scoring are predefined."
      ],
      "metadata": {
        "id": "eb1JJM3MVqqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skorch.callbacks import EpochScoring,EpochTimer\n",
        "auc = EpochScoring(scoring='roc_auc',  lower_is_better=False)\n",
        "acc = EpochScoring(scoring='accuracy', lower_is_better=False)"
      ],
      "metadata": {
        "id": "4k4NQy8FKcDh"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skorch likes to create train and valid split internally but we already have our data splitted. There is a helper function for this *situation*"
      ],
      "metadata": {
        "id": "E4oUKVglgSrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skorch.helper import predefined_split\n",
        "\n",
        "net = NeuralNet(\n",
        "    ...,\n",
        "    train_split=predefined_split(valid_ds)\n",
        ")\n",
        "net.fit(train_ds)"
      ],
      "metadata": {
        "id": "k1WREVLZfRzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we define our classifier"
      ],
      "metadata": {
        "id": "Ny_Wugy5gwrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skorch import NeuralNetClassifier\n",
        "net = NeuralNetClassifier(\n",
        "    model,\n",
        "    criterion=nn.BCELoss,\n",
        "    lr=0.01,\n",
        "    train_split=predefined_split(valid_ds)\n",
        "    # Shuffle training data on each epoch\n",
        "    iterator_train__shuffle=True,\n",
        "    max_epochs=10,\n",
        "    callbacks=[LivePlot],\n",
        "    callbacks=[acc,auc],\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "MrwUROLBzXP8"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aEDpxqNuhIE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.fit(data_train, label_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVZIZ4fSCo1a",
        "outputId": "a470993a-ccdb-48bf-a873-acb51cfaed8c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    accuracy    roc_auc    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ----------  ---------  ------------  -----------  ------------  ------\n",
            "      1      \u001b[36m0.8828\u001b[0m     \u001b[32m0.9149\u001b[0m        \u001b[35m0.5071\u001b[0m       \u001b[31m0.8828\u001b[0m        \u001b[94m0.4289\u001b[0m  5.9792\n",
            "      2      \u001b[36m0.8853\u001b[0m     \u001b[32m0.9220\u001b[0m        \u001b[35m0.4129\u001b[0m       \u001b[31m0.8853\u001b[0m        \u001b[94m0.3834\u001b[0m  5.5010\n",
            "      3      0.8842     \u001b[32m0.9230\u001b[0m        \u001b[35m0.3771\u001b[0m       0.8842        \u001b[94m0.3627\u001b[0m  5.4049\n",
            "      4      \u001b[36m0.8915\u001b[0m     \u001b[32m0.9284\u001b[0m        \u001b[35m0.3576\u001b[0m       \u001b[31m0.8915\u001b[0m        \u001b[94m0.3399\u001b[0m  6.3148\n",
            "      5      0.8898     \u001b[32m0.9298\u001b[0m        \u001b[35m0.3421\u001b[0m       0.8898        \u001b[94m0.3298\u001b[0m  5.7106\n",
            "      6      0.8898     \u001b[32m0.9302\u001b[0m        \u001b[35m0.3318\u001b[0m       0.8898        \u001b[94m0.3228\u001b[0m  6.0488\n",
            "      7      \u001b[36m0.8998\u001b[0m     \u001b[32m0.9322\u001b[0m        \u001b[35m0.3224\u001b[0m       \u001b[31m0.8998\u001b[0m        \u001b[94m0.3101\u001b[0m  5.1378\n",
            "      8      0.8981     \u001b[32m0.9327\u001b[0m        \u001b[35m0.3159\u001b[0m       0.8981        0.3148  6.0672\n",
            "      9      \u001b[36m0.9032\u001b[0m     0.9324        \u001b[35m0.3094\u001b[0m       \u001b[31m0.9032\u001b[0m        \u001b[94m0.2997\u001b[0m  5.2099\n",
            "     10      0.9003     \u001b[32m0.9336\u001b[0m        \u001b[35m0.3037\u001b[0m       0.9003        \u001b[94m0.2967\u001b[0m  6.0591\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=myModel(\n",
              "    (inLay): Linear(in_features=200, out_features=200, bias=True)\n",
              "    (linears): ModuleList(\n",
              "      (0-4): 5 x Linear(in_features=200, out_features=200, bias=True)\n",
              "    )\n",
              "    (bnorms): ModuleList(\n",
              "      (0-4): 5 x BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (outLay): Linear(in_features=200, out_features=1, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.shape,label_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WF-0mP_HJYr",
        "outputId": "a9688fc4-14a8-47c9-fac8-442f5d1aae96"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([100000, 200]), torch.Size([100000]))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pHT0c9XiHy91"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
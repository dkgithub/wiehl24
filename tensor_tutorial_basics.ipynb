{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl6ADLgG3wJB"
      },
      "source": [
        "\n",
        "What is PyTorch?\n",
        "================\n",
        "\n",
        "It’s a Python-based scientific computing package targeted at two sets of\n",
        "audiences:\n",
        "\n",
        "-  A replacement for NumPy to use the power of GPUs\n",
        "-  a deep learning research platform that provides maximum flexibility\n",
        "   and speed\n",
        "\n",
        "## Getting Started\n",
        "\n",
        "### Tensors\n",
        "\n",
        "\n",
        "Tensors are similar to NumPy’s ndarrays, with the addition being that\n",
        "Tensors can also be used on a GPU to accelerate computing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "RDsHX5VX3wJC"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzVFF1Ki3wJC"
      },
      "source": [
        "Construct a 5x3 matrix, uninitialized:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-R6A-UP3wJD",
        "outputId": "5769babc-0477-4176-b235-2dbd929565b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0000e+00, 0.0000e+00, 1.4013e-44],\n",
            "        [9.4591e-39, 2.0211e+21, 3.1672e-41],\n",
            "        [1.5624e-42, 2.7624e-36, 0.0000e+00],\n",
            "        [0.0000e+00, 1.4013e-44, 6.8523e-43],\n",
            "        [2.0211e+21, 3.1672e-41, 3.3631e-44]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.empty(5, 3)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edv3h0Vy3wJD"
      },
      "source": [
        "Construct a randomly initialized matrix:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFFGA49B3wJD",
        "outputId": "072dbf94-d6c3-4b5e-9ce0-ab0409c2ee6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0639, 0.8350, 0.8137],\n",
            "        [0.9438, 0.3267, 0.6345],\n",
            "        [0.3221, 0.8072, 0.2450],\n",
            "        [0.1611, 0.3046, 0.9591],\n",
            "        [0.8094, 0.4070, 0.7709]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JApz_8hx3wJD"
      },
      "source": [
        "Construct a matrix filled zeros and of dtype long:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMUNmSfB3wJD",
        "outputId": "fb09ee1e-b24f-4e01-e63e-c433378f8491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.long)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa9oII9E3wJD"
      },
      "source": [
        "Construct a tensor directly from data:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZcwDW2T3wJD",
        "outputId": "b693c1a8-adf7-481c-bb17-1ba92e3f4395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7rKvxg23wJD"
      },
      "source": [
        "or create a tensor based on an existing tensor. These methods\n",
        "will reuse properties of the input tensor, e.g. dtype, unless\n",
        "new values are provided by user\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1jPbTBz3wJE",
        "outputId": "6ba333f3-2657-446b-a8bb-43aa3b184e3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[-0.9264,  0.9845, -1.4270],\n",
            "        [ 0.5645, -0.1839,  0.6598],\n",
            "        [-0.6687,  0.1758, -0.8071],\n",
            "        [ 0.4930,  1.1076, -0.7585],\n",
            "        [ 0.2252, -0.5155,  1.1213]])\n",
            "torch.FloatTensor\n"
          ]
        }
      ],
      "source": [
        "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(x)\n",
        "\n",
        "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
        "print(x)\n",
        "print(x.type())                               # result has the same size (default float is 32 bits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1P0sIpE3wJE"
      },
      "source": [
        "Get its size:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aHzcdMg3wJE",
        "outputId": "5281df71-f366-427f-a289-06411ddb23d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n",
            "torch.Size([5, 3])\n"
          ]
        }
      ],
      "source": [
        "print(x.size())\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaumE82n3wJE"
      },
      "source": [
        "**Note** `torch.shape` is in fact a tuple, so it supports all tuple operations.\n",
        "\n",
        "## Operations\n",
        "\n",
        "There are multiple syntaxes for operations. In the following\n",
        "example, we will take a look at the addition operation.\n",
        "\n",
        "Addition: syntax 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DQBsKZU3wJE",
        "outputId": "c9344256-1f3e-4356-beb3-d4d155b8cf5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.7104,  1.4484, -0.5723],\n",
            "        [ 1.5640, -0.0256,  1.0924],\n",
            "        [-0.2140,  0.5445, -0.1556],\n",
            "        [ 0.7056,  2.0569, -0.1510],\n",
            "        [ 0.4343,  0.3889,  1.3247]])\n"
          ]
        }
      ],
      "source": [
        "y = torch.rand(5, 3)\n",
        "print(x + y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf5YhiYb3wJE"
      },
      "source": [
        "Addition: syntax 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KOuXZ_k3wJE",
        "outputId": "eac00ffa-643c-4f96-d903-f6c4b2f43861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.7104,  1.4484, -0.5723],\n",
            "        [ 1.5640, -0.0256,  1.0924],\n",
            "        [-0.2140,  0.5445, -0.1556],\n",
            "        [ 0.7056,  2.0569, -0.1510],\n",
            "        [ 0.4343,  0.3889,  1.3247]])\n"
          ]
        }
      ],
      "source": [
        "print(torch.add(x, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "285KzoQY3wJE"
      },
      "source": [
        "Addition: providing an output tensor as argument\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqpHrNWd3wJE",
        "outputId": "baf71b80-4ae2-40b6-e203-ac163e48e408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.7104,  1.4484, -0.5723],\n",
            "        [ 1.5640, -0.0256,  1.0924],\n",
            "        [-0.2140,  0.5445, -0.1556],\n",
            "        [ 0.7056,  2.0569, -0.1510],\n",
            "        [ 0.4343,  0.3889,  1.3247]])\n"
          ]
        }
      ],
      "source": [
        "result = torch.empty(5, 3)\n",
        "torch.add(x, y, out=result)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSVvqWkJ3wJE"
      },
      "source": [
        "Addition: in-place\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E45GNQJA3wJE",
        "outputId": "1dc672ed-ff59-4c2c-802c-a287df84fa0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.7104,  1.4484, -0.5723],\n",
            "        [ 1.5640, -0.0256,  1.0924],\n",
            "        [-0.2140,  0.5445, -0.1556],\n",
            "        [ 0.7056,  2.0569, -0.1510],\n",
            "        [ 0.4343,  0.3889,  1.3247]])\n"
          ]
        }
      ],
      "source": [
        "# adds x to y\n",
        "y.add_(x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9FySb8p3wJF"
      },
      "source": [
        "Since we are handling big data, it may become essential to avoid copying of big objects.\n",
        "\n",
        "Any operation that mutates a tensor in-place is post-fixed with an **`_`**.\n",
        "\n",
        "For example: **`x.copy_(y)`**, **`x.t_()`**, will change **`x`** in-place.\n",
        "\n",
        "You can use standard NumPy-like indexing with all bells and whistles!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF9XeD8O3wJF",
        "outputId": "23155bf5-030a-4a5e-ddba-001e5819b45b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.9845, -0.1839,  0.1758,  1.1076, -0.5155])\n"
          ]
        }
      ],
      "source": [
        "print(x[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5AYJHSe3wJF"
      },
      "source": [
        "Resizing: If you want to resize/reshape tensor, you can use ``torch.view``:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53Z2DaBC3wJF",
        "outputId": "415396dc-1a67-4d4e-84f1-73381387ce27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size(), z.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4w8FZY73wJF"
      },
      "source": [
        "If you have a one element tensor, use ``.item()`` to get the value as a\n",
        "Python number\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb1KpXEJ3wJF",
        "outputId": "9cf9dbd6-b9cb-4cbc-c4ae-9f9439e94222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.3722])\n",
            "1.3721507787704468\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noaLL8Ia3wJF"
      },
      "source": [
        "**Read later:**\n",
        "\n",
        "\n",
        "  100+ Tensor operations, including transposing, indexing, slicing,\n",
        "  mathematical operations, linear algebra, random numbers, etc.,\n",
        "  are described\n",
        "  ([torch tensors](https://pytorch.org/docs/torch))\n",
        "\n",
        "NumPy Bridge\n",
        "------------\n",
        "\n",
        "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
        "\n",
        "The Torch Tensor and NumPy array will **share** their underlying memory\n",
        "locations, and changing one will change the other.\n",
        "\n",
        "## Converting a Torch Tensor to a NumPy Array\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpLlnOe_3wJF",
        "outputId": "71a30f31-33d8-49ac-8165-dd18a8957534"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "a = torch.ones(5)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg8LwO3_3wJF",
        "outputId": "8afed043-19e6-4bb7-de93-b05efa01ed3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "b = a.numpy()\n",
        "print(b)\n",
        "type(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjgrusLf3wJF"
      },
      "source": [
        "See how the numpy array is changed when we modify the tensor in-place.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdI5gMgg3wJF",
        "outputId": "61934b3f-fe4b-47c5-8942-9da77ed8983b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3., 3.])\n",
            "numpy.ndarray [3. 3. 3. 3. 3.]\n"
          ]
        }
      ],
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print('numpy.ndarray',b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cG1yGLa3wJF"
      },
      "source": [
        "## Converting NumPy Array to Torch Tensor\n",
        "\n",
        "See how changing the np array changed the Torch Tensor automatically\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vsw8c4pf3wJG",
        "outputId": "1683444b-b14e-4cf5-d010-63925c65cdff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJGiJSw63wJG"
      },
      "source": [
        "All the Tensors on the CPU except a CharTensor support converting to\n",
        "NumPy and back and forth.\n",
        "\n",
        "CUDA Tensors\n",
        "------------\n",
        "\n",
        "Tensors can be moved onto any device using the ``.to`` method.\n",
        "\n",
        "For this on Collab you must select a Runtime->Change Runtime-> T4 GPU, if available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vkat8M93wJG",
        "outputId": "fc0eb82e-f0bb-4baa-9939-9c7d85a21cb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.], device='cuda:0') torch.cuda.FloatTensor\n",
            "tensor([2.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.])\n",
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "device=\"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z,z.type())\n",
        "    print(z.to(\"cpu\", torch.double))        # ``.to`` can also change dtype together!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikbob-sV3wJG"
      },
      "source": [
        "### If you want to write device independent code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FTBpptK3wJG",
        "outputId": "b8d2df34-a4cf-4a45-ae3e-698bcd4a65e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "x = x.to(device)  # this will go to GPU if available otherwise it doesn't change anything\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T6VshH43wJG"
      },
      "source": [
        "Check the following link for working with multiple GPUs\n",
        "\n",
        "https://pytorch.org/docs/stable/notes/cuda.html#cuda-semantics\n",
        "\n",
        "## Explicit cpu/cuda syntax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdWEEYEh3wJG",
        "outputId": "bbdba826-0f3f-4343-e610-f9ca64c7a817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current device index: 1. Total number of devices: 1\n",
            "\n",
            "On GPU: z = \n",
            "tensor([2.], device='cuda:0')\n",
            "Type  torch.cuda.FloatTensor\n",
            "Notice the type has now become torch.cuda.FloatTensor.\n",
            "\n",
            "On CPU: z = tensor([2.])\n",
            "Type  torch.FloatTensor\n"
          ]
        }
      ],
      "source": [
        "# Send a pyTorch tensor to GPU\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # How many GPUs do we have?\n",
        "    num_gpus    = torch.cuda.device_count()\n",
        "    current_gpu = torch.cuda.device_count()\n",
        "    print(\"Current device index: {}. Total number of devices: {}\".format(current_gpu,num_gpus))\n",
        "    torch.cuda.set_device(0)\n",
        "    z = z.cuda()\n",
        "\n",
        "    print(\"\\nOn GPU: z = \\n{}\".format(z))\n",
        "    print(\"Type \",z.type() ) # that's different to type(z) python does not know the difference\n",
        "\n",
        "    print(\"Notice the type has now become torch.cuda.FloatTensor.\")\n",
        "    if num_gpus>=2:\n",
        "        # Now let's send it to a different GPU if available\n",
        "        print(\"Switching to a different device...\")\n",
        "        torch.cuda.set_device(1)\n",
        "        print(\"Current device index: {}\".format(torch.cuda.current_device()))\n",
        "        z = z.cuda()\n",
        "        print(\"On a different GPU: z = {}\".format(z))\n",
        "        print(\"Type \", z.type())\n",
        "else:\n",
        "    print(\"No GPU available\")\n",
        "# Send Tensor back to CPU\n",
        "z = z.cpu()\n",
        "print(\"\\nOn CPU: z = {}\".format(z))\n",
        "print(\"Type \",z.type())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rPhdUhsANbd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torch tensors can be coverted between numpy but only if theu are on **cpu**. First transfer to cpu then comvert to numpy."
      ],
      "metadata": {
        "id": "CMSr0CkkNc_7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "ptm8qBNm3wJG",
        "outputId": "ee6c31d6-d5ee-4fb9-f937-b08975a54f1a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-100f6ddc89fb>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Converted to numpy, z = {}\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ],
      "source": [
        "# Convert Tensor to Numpy array and vice versa\n",
        "import numpy as np\n",
        "z = x + y\n",
        "z = z.numpy()\n",
        "print(\"Converted to numpy, z = {}\\n{}\".format(type(z), z))\n",
        "\n",
        "z = torch.from_numpy(z)\n",
        "print( \"Converted to Tensor, z = {}\".format(z))\n",
        "\n",
        "# Note that the conversion is not possible when the Tensor is on GPU\n",
        "z = z.cuda()\n",
        "z = z.numpy()  # <<<< create error on purpose!!\n",
        "#try:\n",
        "#    z = z.numpy()\n",
        "#except RuntimeError as e:\n",
        "#    print( \"Error: {}\".format(e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwN1oLMh3wJG"
      },
      "source": [
        "### Timing\n",
        "The speed improvement on GPU is subject of the next tutorial torch_tensor_tutorial_timing.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThRYSLsu3wJG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}